{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a step by step guide about how to train a deep neural network (DNN) in the DeepDeconv framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the sys.path in order to be able to import our modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../python'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## extra imports to set GPU options\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# This line is optional, don't add it unless you really need to set a limit on the memory available for your process\n",
    "# For instance, if you want to train 2 DNNs on the same GPU without one overlapping the memory needed by the other\n",
    "# Change the value to set the percentage of memory allocated\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.75 \n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "# Now you can create/load your DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the class of the network. This class must inherit from the DeepNet superclass. The method build_model has to be redefined in the child class with the wanted architecture. In our work, we use the network defined in deconvnNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from DeepDeconv.deepnetFCS.DeconvNet_custom import DeconvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cben-ali/Programs/deep-deconv/python/DeepDeconv/deepnetFCS/DeconvNet_custom.py:293: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=[<tf.Tenso...)`\n",
      "  self.model = Model(input = [inputs,window,norm], outputs =output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss/conv2d_4_loss/strided_slice:0\", shape=(96, 96), dtype=float32) Tensor(\"window:0\", shape=(?, 96, 96, 1), dtype=float32) Tensor(\"norm:0\", shape=(?, 6, 1, 1), dtype=float32) Tensor(\"loss/conv2d_4_loss/sub:0\", shape=(?, 96, 96, ?), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 96, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 96, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 96, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 96, 96, 4)    416         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 96, 96, 4)    16          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 96, 4)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 96, 96, 4)    52          activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 96, 8)    0           separable_conv2d_1[0][0]         \n",
      "                                                                 separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 40)   0           conv2d_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 96, 96, 40)   160         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 96, 40)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 40)   1600        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 48, 48, 40)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 48, 48, 40)   160         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 48, 48, 40)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 48, 48, 4)    520         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 48, 48, 4)    16          separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 48, 48, 4)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 48, 48, 4)    52          activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 48, 8)    0           separable_conv2d_3[0][0]         \n",
      "                                                                 separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 96, 96, 8)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 96, 96, 8)    264         up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 96, 48)   0           conv2d_3[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 96, 96, 48)   192         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 96, 96, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 96, 96, 4)    624         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 96, 96, 4)    16          separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 96, 96, 4)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 96, 96, 4)    52          activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 96, 96, 8)    0           separable_conv2d_5[0][0]         \n",
      "                                                                 separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 96, 96, 8)    32          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 96, 8)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 96, 96, 1)    9           activation_8[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,597\n",
      "Trainable params: 4,237\n",
      "Non-trainable params: 360\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb_scales = 2 #4\n",
    "growth_rate = 4 #12\n",
    "nb_layers_per_block = [2,2]#[4,5,6,7]\n",
    "activation_function= 'relu' #'relu'\n",
    "gamma=0.1\n",
    "shape_constraint=True\n",
    "atrou=False\n",
    "resNet=False\n",
    "layer_string='layer{0}'.format(nb_layers_per_block[0])\n",
    "\n",
    "\n",
    "for k in range(1,len(nb_layers_per_block)):\n",
    "    layer_string+='x{0}'.format(nb_layers_per_block[k])\n",
    "network_name='ShapeNet2D_claire_sc{0}_{1}_{2}_growthRate{3}_with_shape'.format(nb_scales,layer_string,\n",
    "                                                                              activation_function,growth_rate)\n",
    "if resNet:\n",
    "    network_name+='_resNet'\n",
    "\n",
    "dnn = DeconvNet(network_name = network_name, img_rows = 96, img_cols = 96, model_file='', verbose=True,\n",
    "                nb_scales=nb_scales, growth_rate=growth_rate, nb_layers_per_block=nb_layers_per_block, \n",
    "                activation_function=activation_function,resNet=resNet,atrou=atrou,gamma=gamma,\n",
    "                shape_constraint=shape_constraint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have our network ready, the next step is to train it.\n",
    "\n",
    "During my internship, I used .fits files containing 10 000 galaxies each of size (96x96). Each file contains 4 HDU:\n",
    "HDU 0: noisy convolved galaxies (never used those)\n",
    "HDU 1: noiseless convolved galaxies\n",
    "HDU 2: target galaxies convolved with gaussian PSF of FWHM=0.15 (irrelevent)\n",
    "HDU 3: Euclid PSFs\n",
    "HDU 4 target galaxies convolved with gaussian PSF of FWHM=0.07\n",
    "Each HDU is one big image 9600x9600 containing the mosaic of the 10 000 samples\n",
    "\n",
    "The DeepNet class has methods to train the network. 3 alternatives are possible:\n",
    "\n",
    "-The data is already loaded in python, use:\n",
    "\n",
    "    train(train_data, model_file = '', epochs=20, batch_size=32, validation_split=0.1)\n",
    "train_data is a numpy array of shape (2, nb_samples, img_row, img_col, 1), the first dimension containing all the inputs of the network and the second dimension the ground truths. validation_split set the percentage of data for the valisation set. This method load your whole dataset directly so if you work with a huge set, you will pobably run out of memory, especially on GPU. You should try to opt for the other methods if possible.\n",
    "    \n",
    "-The data is already preprocessed inside .npy files and you want to load it one batch at a time:\n",
    "\n",
    "    train_generator_npy(train_files, validation_file, epochs=20, batch_size=32, nb_img_per_file=10000)\n",
    "as above, each file must contain an array of shape (2, nb_img_per_file, img_row, img_col, 1). A validation_file containing the validation set must be provided too.\n",
    "\n",
    "-You want to read the fits and process the data on the fly:\n",
    "\n",
    "    train_generator(train_files, validation_file, epochs=20, batch_size=32,\n",
    "                        nb_img_per_file=10000, validation_set_size=10000,\n",
    "                        noise_std=None, SNR=None,\n",
    "                        noiseless_obs_hdu=0, targets_hdu=0, psf_hdu=0,\n",
    "                        image_dim=96, image_per_row=100,\n",
    "                        deconv_mode=None, rho_fista=1e-3)\n",
    "so here you provides the list of fits files inside train_files and one validation file inside validation_files. You use hdu parameters to extract the desired values inside the fits. Functions inside batch_utils.py will automatically process the data from the fits and convert it to numpy array of the correct shape for the network.\n",
    "\n",
    "In our case, we use this function as follows:\n",
    "\n",
    "train_files (list of str): list of all our fits files containing the training set.\n",
    "\n",
    "validation_file (str): validation set inside a fits file.\n",
    "\n",
    "noise_std (int or list of 2 ints or None): int for constant noise, list of 2 ints [min_std, max_std] for a range of sigma and None if you want to use SNR instead.\n",
    "\n",
    "SNR (int or list of 2 ints or None): same as noise_std but you input SNR values instead.\n",
    "\n",
    "noiseless_obs_hdu (int): HDU in which the noiseless convolved galaxies are. Noise will be added according to the previous parameters.\n",
    "\n",
    "targets_hdu (int): HDU containing the ground truths.\n",
    "\n",
    "psf_hdu (int): HDU containing the PSFs.\n",
    "\n",
    "image_dim (int): nb of rows/columns of each galaxy (we use square images).\n",
    "\n",
    "image_per_row (int): images per row inside the fits mosaic (we use square mosaic in our fits files).\n",
    "\n",
    "deconv_mode (None or 'TIKHONOV' or 'FISTA'): set the preprocessing to be applied on the input of the network.\n",
    "\n",
    "rho_fista (float): only needed as a parameter for FISTA pre-processing.\n",
    "\n",
    "\n",
    "The 2nd method is the best if you have limited computational ressources (but you have to do the preprocessing beforehand to generate all the .npy files).\n",
    "The 3rd method provides an efficient method to do the pre-processing of each batch right before feeding it to the network for training. We use this method as an example in the following cells.\n",
    "Both use the fit_generator method inside the model class in Keras. This function is the best to train the network without overloading your memory. It requires to define a generator, see dynamic_batches in batch_utils.npy for an example of implementation.\n",
    "\n",
    "Note that for all the methods, a callback save automatically the network which got the best result on validation data (using MSE). If model_file is left empty, the model will be saved in the current working directory as \"network_name.hdf5\". Input the string containing the wanted path/name in model_file (with .hdf5 extension) to chose save location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-0-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-1-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-10-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-11-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-12-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-13-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-14-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-15-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-16-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-17-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-18-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-19-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-2-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-20-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-3-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-4-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-5-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-6-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-7-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-8-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-9-multihdu.fits']\n",
      "['/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_0.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_1.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_10.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_11.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_12.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_13.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_14.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_15.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_16.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_17.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_18.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_19.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_2.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_20.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_3.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_4.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_5.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_6.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_7.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_8.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_9.fits']\n",
      "Model will be saved at /home/cben-ali/Programs/deep-deconv/tutorials/ShapeNet2D_claire_sc2_layer2x2_relu_growthRate4_with_shape.hdf5\n",
      "Memory usage for the model + one batch (GB): 0.570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cben-ali/Programs/deep-deconv/python/DeepDeconv/deepnetFCS/DeepNet.py:195: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=20, validation_data=([array([[..., verbose=1, callbacks=[<keras.ca..., initial_epoch=0, steps_per_epoch=5947)`\n",
      "  initial_epoch=initial_epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5325/5947 [=========================>....] - ETA: 5:31 - loss: 120.7836 - mean_squared_error: 0.2657 - shape_metric: 120.5179"
     ]
    }
   ],
   "source": [
    "#Input the directory containing the fits file\n",
    "data_directory = '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/'\n",
    "write_path=\"/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/\"\n",
    "\n",
    "#Retrieves the list of all the files\n",
    "import glob\n",
    "\n",
    "gal_files = glob.glob(data_directory+'image-*-multihdu.fits')\n",
    "gal_files.sort()\n",
    "print(gal_files)\n",
    "\n",
    "win_files = glob.glob(write_path+'window/'+'Gaussian*')\n",
    "win_files.sort()\n",
    "print(win_files)\n",
    "\n",
    "\n",
    "SNR = [20,100]#Range of SNR simulated\n",
    "noiseless_img_hdu = 0\n",
    "psf_hdu = 1\n",
    "targets_hdu = 2\n",
    "deconv_mode = 'TIKHONOV'\n",
    "\n",
    "#Train with the image-000-0.fits as validation and all the other files as training set\n",
    "#dnn.train_generator(gal_files[1:], gal_files[0], epochs=20, batch_size=32,\n",
    "#                        nb_img_per_file=10000, validation_set_size=10000,\n",
    "#                        noise_std=None, SNR=SNR, model_file='',\n",
    "#                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu, psf_hdu=psf_hdu,\n",
    "#                        image_dim=96, image_per_row=100,\n",
    "#                        deconv_mode=deconv_mode)\n",
    "#Here the number of epochs is set to 2, should be on the order of 20 at the end\n",
    "\n",
    "dnn.train_generator(gal_files[2:], gal_files[1], epochs=20, batch_size=32,\n",
    "                        model_file='', nb_img_per_file=10000, \n",
    "                        validation_set_size=10000, noise_std=None, SNR=SNR, \n",
    "                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu,\n",
    "                        psf_hdu=psf_hdu, image_dim=96, image_per_row=100,\n",
    "                        deconv_mode=deconv_mode, win_validation_filename=win_files[1],\n",
    "                        win_filename=win_files[2:],win_hdu=0,mom_hdu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_scales = 2 #4\n",
    "growth_rate = 4 #12\n",
    "nb_layers_per_block = [2,2]#[4,5,6,7]\n",
    "activation_function= 'relu' #'relu'\n",
    "\n",
    "atrou=False\n",
    "resNet=False\n",
    "layer_string='layer{0}'.format(nb_layers_per_block[0])\n",
    "\n",
    "\n",
    "for k in range(1,len(nb_layers_per_block)):\n",
    "    layer_string+='x{0}'.format(nb_layers_per_block[k])\n",
    "network_name='ShapeNet2D_claire_sc{0}_{1}_{2}_growthRate{3}'.format(nb_scales,layer_string,\n",
    "                                                                              activation_function,growth_rate)\n",
    "if resNet:\n",
    "    network_name+='_resNet'\n",
    "\n",
    "dnn= DeconvNet(network_name = network_name, img_rows = 96, img_cols = 96, model_file='', verbose=True,\n",
    "                nb_scales=nb_scales, growth_rate=growth_rate, nb_layers_per_block=nb_layers_per_block, \n",
    "                activation_function=activation_function,resNet=resNet,atrou=atrou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Input the directory containing the fits file\n",
    "data_directory = '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/'\n",
    "write_path=\"/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/\"\n",
    "\n",
    "#Retrieves the list of all the files\n",
    "import glob\n",
    "\n",
    "gal_files = glob.glob(data_directory+'image-*-multihdu.fits')\n",
    "gal_files.sort()\n",
    "print(gal_files)\n",
    "\n",
    "win_files = glob.glob(write_path+'window/'+'Gaussian*')\n",
    "win_files.sort()\n",
    "print(win_files)\n",
    "\n",
    "\n",
    "SNR = [20,100]#Range of SNR simulated\n",
    "noiseless_img_hdu = 0\n",
    "psf_hdu = 1\n",
    "targets_hdu = 2\n",
    "deconv_mode = 'TIKHONOV'\n",
    "\n",
    "#Train with the image-000-0.fits as validation and all the other files as training set\n",
    "#dnn.train_generator(gal_files[1:], gal_files[0], epochs=20, batch_size=32,\n",
    "#                        nb_img_per_file=10000, validation_set_size=10000,\n",
    "#                        noise_std=None, SNR=SNR, model_file='',\n",
    "#                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu, psf_hdu=psf_hdu,\n",
    "#                        image_dim=96, image_per_row=100,\n",
    "#                        deconv_mode=deconv_mode)\n",
    "#Here the number of epochs is set to 2, should be on the order of 20 at the end\n",
    "\n",
    "dnn.train_generator(gal_files[2:], gal_files[1], epochs=20, batch_size=32,\n",
    "                        model_file='', nb_img_per_file=10000, \n",
    "                        validation_set_size=10000, noise_std=None, SNR=SNR, \n",
    "                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu,\n",
    "                        psf_hdu=psf_hdu, image_dim=96, image_per_row=100,\n",
    "                        deconv_mode=deconv_mode, win_validation_filename=win_files[1],\n",
    "                        win_filename=win_files[2:],win_hdu=0,mom_hdu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cben-ali/Programs/deep-deconv/python/DeepDeconv/deepnetFCS/DeconvNet_custom.py:293: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=[<tf.Tenso...)`\n",
      "  self.model = Model(input = [inputs,window,norm], outputs =output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss/conv2d_8_loss/strided_slice:0\", shape=(96, 96), dtype=float32) Tensor(\"window:0\", shape=(?, 96, 96, 1), dtype=float32) Tensor(\"norm:0\", shape=(?, 6, 1, 1), dtype=float32) Tensor(\"loss/conv2d_8_loss/sub:0\", shape=(?, 96, 96, ?), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 96, 96, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 96, 96, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 96, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 96, 96, 12)   672         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 96, 96, 12)   48          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 96, 12)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 96, 96, 12)   252         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 96, 24)   0           separable_conv2d_1[0][0]         \n",
      "                                                                 separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 96, 96, 24)   96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 96, 24)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 96, 96, 12)   504         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 36)   0           concatenate_1[0][0]              \n",
      "                                                                 separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 96, 96, 36)   144         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 96, 96, 36)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 96, 96, 12)   756         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 96, 96, 48)   0           concatenate_2[0][0]              \n",
      "                                                                 separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 96, 80)   0           conv2d_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 96, 96, 80)   320         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 96, 96, 80)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 96, 96, 80)   6400        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 48, 48, 80)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 48, 48, 80)   320         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 48, 48, 80)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 48, 48, 12)   1680        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 48, 48, 12)   48          separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 48, 48, 12)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 48, 48, 12)   252         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 48, 48, 24)   0           separable_conv2d_5[0][0]         \n",
      "                                                                 separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 48, 48, 24)   96          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 48, 48, 24)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 48, 48, 12)   504         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 48, 48, 36)   0           concatenate_5[0][0]              \n",
      "                                                                 separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 48, 48, 36)   144         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 48, 48, 36)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 48, 48, 12)   756         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 48, 48, 48)   0           concatenate_6[0][0]              \n",
      "                                                                 separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 48, 48, 48)   192         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 48, 48, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 48, 48, 12)   1008        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 48, 48, 60)   0           concatenate_7[0][0]              \n",
      "                                                                 separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 48, 48, 140)  0           average_pooling2d_1[0][0]        \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 48, 48, 140)  560         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 48, 48, 140)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 48, 48, 140)  19600       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 24, 24, 140)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 24, 24, 140)  560         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 24, 24, 140)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 24, 24, 12)   2940        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 24, 24, 12)   48          separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 24, 24, 12)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 24, 24, 12)   252         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 24, 24, 24)   0           separable_conv2d_10[0][0]        \n",
      "                                                                 separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 24, 24, 24)   96          concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 24, 24, 24)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 24, 24, 12)   504         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 24, 24, 36)   0           concatenate_10[0][0]             \n",
      "                                                                 separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 24, 24, 36)   144         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 24, 24, 36)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 24, 24, 12)   756         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 24, 24, 48)   0           concatenate_11[0][0]             \n",
      "                                                                 separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 24, 24, 48)   192         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 24, 24, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 24, 24, 12)   1008        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 24, 24, 60)   0           concatenate_12[0][0]             \n",
      "                                                                 separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 24, 24, 60)   240         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 24, 24, 60)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 24, 24, 12)   1260        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 24, 24, 72)   0           concatenate_13[0][0]             \n",
      "                                                                 separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 24, 24, 212)  0           average_pooling2d_2[0][0]        \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 24, 24, 212)  848         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 24, 24, 212)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 24, 24, 212)  44944       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 212)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 12, 212)  848         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 12, 12, 212)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 12, 12, 12)   4452        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 12, 12, 12)   48          separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 12, 12, 12)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 12, 12, 12)   252         activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 12, 12, 24)   0           separable_conv2d_16[0][0]        \n",
      "                                                                 separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 12, 12, 24)   96          concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 12, 12, 24)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 12, 12, 12)   504         activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 12, 12, 36)   0           concatenate_16[0][0]             \n",
      "                                                                 separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 12, 12, 36)   144         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 12, 12, 36)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 12, 12, 12)   756         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 12, 12, 48)   0           concatenate_17[0][0]             \n",
      "                                                                 separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 12, 12, 48)   192         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 12, 12, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 12, 12, 12)   1008        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 12, 12, 60)   0           concatenate_18[0][0]             \n",
      "                                                                 separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 12, 12, 60)   240         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 12, 12, 60)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 12, 12, 12)   1260        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 12, 12, 72)   0           concatenate_19[0][0]             \n",
      "                                                                 separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 12, 12, 72)   288         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 12, 12, 72)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 12, 12, 12)   1512        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 12, 12, 84)   0           concatenate_20[0][0]             \n",
      "                                                                 separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 24, 24, 84)   0           concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 24, 24, 84)   28308       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 24, 24, 296)  0           conv2d_5[0][0]                   \n",
      "                                                                 concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 24, 24, 296)  1184        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 24, 24, 296)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 24, 24, 12)   6216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 24, 24, 12)   48          separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 24, 24, 12)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 24, 24, 12)   252         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 24, 24, 24)   0           separable_conv2d_23[0][0]        \n",
      "                                                                 separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 24, 24, 24)   96          concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 24, 24, 24)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 24, 24, 12)   504         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 24, 24, 36)   0           concatenate_23[0][0]             \n",
      "                                                                 separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 24, 24, 36)   144         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 24, 24, 36)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 24, 24, 12)   756         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 24, 24, 48)   0           concatenate_24[0][0]             \n",
      "                                                                 separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 24, 24, 48)   192         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 24, 24, 48)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, 24, 24, 12)   1008        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 24, 24, 60)   0           concatenate_25[0][0]             \n",
      "                                                                 separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 24, 24, 60)   240         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 24, 24, 60)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, 24, 24, 12)   1260        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 24, 24, 72)   0           concatenate_26[0][0]             \n",
      "                                                                 separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 48, 48, 72)   0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 48, 48, 72)   20808       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 48, 48, 212)  0           conv2d_6[0][0]                   \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 48, 48, 212)  848         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 48, 48, 212)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, 48, 48, 12)   4452        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 48, 48, 12)   48          separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 48, 48, 12)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, 48, 48, 12)   252         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 48, 48, 24)   0           separable_conv2d_29[0][0]        \n",
      "                                                                 separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 48, 48, 24)   96          concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 48, 48, 24)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, 48, 48, 12)   504         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 48, 48, 36)   0           concatenate_29[0][0]             \n",
      "                                                                 separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 48, 48, 36)   144         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 48, 48, 36)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, 48, 48, 12)   756         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 48, 48, 48)   0           concatenate_30[0][0]             \n",
      "                                                                 separable_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 48, 48, 48)   192         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 48, 48, 48)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_33 (SeparableC (None, 48, 48, 12)   1008        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 48, 48, 60)   0           concatenate_31[0][0]             \n",
      "                                                                 separable_conv2d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 96, 96, 60)   0           concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 96, 60)   14460       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 96, 96, 140)  0           conv2d_7[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 96, 96, 140)  560         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 96, 96, 140)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_34 (SeparableC (None, 96, 96, 12)   2940        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 96, 96, 12)   48          separable_conv2d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 96, 96, 12)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_35 (SeparableC (None, 96, 96, 12)   252         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 96, 96, 24)   0           separable_conv2d_34[0][0]        \n",
      "                                                                 separable_conv2d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 96, 96, 24)   96          concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 96, 96, 24)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_36 (SeparableC (None, 96, 96, 12)   504         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 96, 96, 36)   0           concatenate_34[0][0]             \n",
      "                                                                 separable_conv2d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 96, 96, 36)   144         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 96, 96, 36)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_37 (SeparableC (None, 96, 96, 12)   756         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 96, 96, 48)   0           concatenate_35[0][0]             \n",
      "                                                                 separable_conv2d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 96, 96, 48)   192         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 96, 96, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 96, 1)    49          activation_41[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 189,477\n",
      "Trainable params: 184,301\n",
      "Non-trainable params: 5,176\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb_scales = 4 #4\n",
    "growth_rate = 12 #12\n",
    "nb_layers_per_block = [4,5,6,7]#[4,5,6,7]\n",
    "activation_function= 'relu' #'relu'\n",
    "gamma=0.1\n",
    "shape_constraint=True\n",
    "atrou=False\n",
    "resNet=False\n",
    "layer_string='layer{0}'.format(nb_layers_per_block[0])\n",
    "\n",
    "\n",
    "for k in range(1,len(nb_layers_per_block)):\n",
    "    layer_string+='x{0}'.format(nb_layers_per_block[k])\n",
    "network_name='ShapeNet2D_claire_sc{0}_{1}_{2}_growthRate{3}_with_shape_gamma{4}'.format(nb_scales,layer_string,\n",
    "                                                                                        activation_function,growth_rate,gamma)\n",
    "if resNet:\n",
    "    network_name+='_resNet'\n",
    "\n",
    "dnn= DeconvNet(network_name = network_name, img_rows = 96, img_cols = 96, model_file='', verbose=True,\n",
    "                nb_scales=nb_scales, growth_rate=growth_rate, nb_layers_per_block=nb_layers_per_block, \n",
    "                activation_function=activation_function,resNet=resNet,atrou=atrou,gamma=gamma,\n",
    "                shape_constraint=shape_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-0-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-1-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-10-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-11-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-12-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-13-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-14-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-15-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-16-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-17-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-18-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-19-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-2-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-20-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-3-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-4-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-5-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-6-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-7-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-8-multihdu.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/image-shfl-9-multihdu.fits']\n",
      "['/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_0.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_1.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_10.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_11.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_12.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_13.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_14.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_15.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_16.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_17.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_18.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_19.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_2.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_20.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_3.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_4.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_5.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_6.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_7.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_8.fits', '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/window/Gaussian_window_claire_9.fits']\n",
      "Model will be saved at /home/cben-ali/Programs/deep-deconv/tutorials/ShapeNet2D_claire_sc4_layer4x5x6x7_relu_growthRate12_with_shape_gamma0.1.hdf5\n",
      "Memory usage for the model + one batch (GB): 2.809000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cben-ali/Programs/deep-deconv/python/DeepDeconv/deepnetFCS/DeepNet.py:195: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=20, validation_data=([array([[..., verbose=1, callbacks=[<keras.ca..., initial_epoch=0, steps_per_epoch=5947)`\n",
      "  initial_epoch=initial_epoch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5947/5947 [==============================] - 4591s 772ms/step - loss: 219.5699 - mean_squared_error: 0.1446 - shape_metric: 219.4253 - val_loss: 30.5096 - val_mean_squared_error: 0.0450 - val_shape_metric: 30.4647\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 30.50965, saving model to ShapeNet2D_claire_sc4_layer4x5x6x7_relu_growthRate12_with_shape_gamma0.1.hdf5\n",
      "2019-06-03_11:30:11 - Epoch: 1, val_loss: 30.509645, val_mean_squared_error: 0.044953, val_shape_metric: 30.464692, loss: 219.832324, mean_squared_error: 0.144616, shape_metric: 219.687707\n",
      "Epoch 2/20\n",
      "5947/5947 [==============================] - 4462s 750ms/step - loss: 23.8928 - mean_squared_error: 0.0287 - shape_metric: 23.8640 - val_loss: 2517.5113 - val_mean_squared_error: 0.3113 - val_shape_metric: 2517.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 30.50965\n",
      "2019-06-03_12:44:33 - Epoch: 2, val_loss: 2517.511260, val_mean_squared_error: 0.311280, val_shape_metric: 2517.199982, loss: 23.870985, mean_squared_error: 0.028722, shape_metric: 23.842263\n",
      "Epoch 3/20\n",
      "5947/5947 [==============================] - 4355s 732ms/step - loss: 15.1108 - mean_squared_error: 0.0228 - shape_metric: 15.0879 - val_loss: 18.6505 - val_mean_squared_error: 0.0121 - val_shape_metric: 18.6384\n",
      "\n",
      "Epoch 00003: val_loss improved from 30.50965 to 18.65051, saving model to ShapeNet2D_claire_sc4_layer4x5x6x7_relu_growthRate12_with_shape_gamma0.1.hdf5\n",
      "2019-06-03_13:57:09 - Epoch: 3, val_loss: 18.650512, val_mean_squared_error: 0.012068, val_shape_metric: 18.638444, loss: 15.113060, mean_squared_error: 0.022821, shape_metric: 15.090239\n",
      "Epoch 4/20\n",
      "5947/5947 [==============================] - 4473s 752ms/step - loss: 10.9217 - mean_squared_error: 0.0104 - shape_metric: 10.9113 - val_loss: 18.0357 - val_mean_squared_error: 0.0132 - val_shape_metric: 18.0225\n",
      "\n",
      "Epoch 00004: val_loss improved from 18.65051 to 18.03570, saving model to ShapeNet2D_claire_sc4_layer4x5x6x7_relu_growthRate12_with_shape_gamma0.1.hdf5\n",
      "2019-06-03_15:11:43 - Epoch: 4, val_loss: 18.035705, val_mean_squared_error: 0.013181, val_shape_metric: 18.022523, loss: 10.909106, mean_squared_error: 0.010362, shape_metric: 10.898744\n",
      "Epoch 5/20\n",
      "5637/5947 [===========================>..] - ETA: 3:49 - loss: 9.4823 - mean_squared_error: 0.0066 - shape_metric: 9.4757"
     ]
    }
   ],
   "source": [
    "#Input the directory containing the fits file\n",
    "data_directory = '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/'\n",
    "write_path=\"/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/\"\n",
    "\n",
    "#Retrieves the list of all the files\n",
    "import glob\n",
    "\n",
    "gal_files = glob.glob(data_directory+'image-*-multihdu.fits')\n",
    "gal_files.sort()\n",
    "print(gal_files)\n",
    "\n",
    "win_files = glob.glob(write_path+'window/'+'Gaussian*')\n",
    "win_files.sort()\n",
    "print(win_files)\n",
    "\n",
    "\n",
    "SNR = [20,100]#Range of SNR simulated\n",
    "noiseless_img_hdu = 0\n",
    "psf_hdu = 1\n",
    "targets_hdu = 2\n",
    "deconv_mode = 'TIKHONOV'\n",
    "\n",
    "#Train with the image-000-0.fits as validation and all the other files as training set\n",
    "#dnn.train_generator(gal_files[1:], gal_files[0], epochs=20, batch_size=32,\n",
    "#                        nb_img_per_file=10000, validation_set_size=10000,\n",
    "#                        noise_std=None, SNR=SNR, model_file='',\n",
    "#                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu, psf_hdu=psf_hdu,\n",
    "#                        image_dim=96, image_per_row=100,\n",
    "#                        deconv_mode=deconv_mode)\n",
    "#Here the number of epochs is set to 2, should be on the order of 20 at the end\n",
    "\n",
    "dnn.train_generator(gal_files[2:], gal_files[1], epochs=20, batch_size=32,\n",
    "                        model_file='', nb_img_per_file=10000, \n",
    "                        validation_set_size=10000, noise_std=None, SNR=SNR, \n",
    "                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu,\n",
    "                        psf_hdu=psf_hdu, image_dim=96, image_per_row=100,\n",
    "                        deconv_mode=deconv_mode, win_validation_filename=win_files[1],\n",
    "                        win_filename=win_files[2:],win_hdu=0,mom_hdu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_scales = 4 #4\n",
    "growth_rate = 12 #12\n",
    "nb_layers_per_block = [5,5,5,5]#[4,5,6,7]\n",
    "activation_function= 'relu' #'relu'\n",
    "gamma=0.1\n",
    "shape_constraint=True\n",
    "atrou=False\n",
    "resNet=False\n",
    "layer_string='layer{0}'.format(nb_layers_per_block[0])\n",
    "\n",
    "\n",
    "for k in range(1,len(nb_layers_per_block)):\n",
    "    layer_string+='x{0}'.format(nb_layers_per_block[k])\n",
    "network_name='ShapeNet2D_claire_sc{0}_{1}_{2}_growthRate{3}_with_shape_gamma{4}'.format(nb_scales,layer_string,\n",
    "                                                                               activation_function,growth_rate,gamma)\n",
    "if resNet:\n",
    "    network_name+='_resNet'\n",
    "\n",
    "dnn= DeconvNet(network_name = network_name, img_rows = 96, img_cols = 96, model_file='', verbose=True,\n",
    "                nb_scales=nb_scales, growth_rate=growth_rate, nb_layers_per_block=nb_layers_per_block, \n",
    "                activation_function=activation_function,resNet=resNet,atrou=atrou,gamma=gamma,\n",
    "                shape_constraint=shape_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the directory containing the fits file\n",
    "data_directory = '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/'\n",
    "write_path=\"/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/\"\n",
    "\n",
    "#Retrieves the list of all the files\n",
    "import glob\n",
    "\n",
    "gal_files = glob.glob(data_directory+'image-*-multihdu.fits')\n",
    "gal_files.sort()\n",
    "print(gal_files)\n",
    "\n",
    "win_files = glob.glob(write_path+'window/'+'Gaussian*')\n",
    "win_files.sort()\n",
    "print(win_files)\n",
    "\n",
    "\n",
    "SNR = [20,100]#Range of SNR simulated\n",
    "noiseless_img_hdu = 0\n",
    "psf_hdu = 1\n",
    "targets_hdu = 2\n",
    "deconv_mode = 'TIKHONOV'\n",
    "\n",
    "#Train with the image-000-0.fits as validation and all the other files as training set\n",
    "#dnn.train_generator(gal_files[1:], gal_files[0], epochs=20, batch_size=32,\n",
    "#                        nb_img_per_file=10000, validation_set_size=10000,\n",
    "#                        noise_std=None, SNR=SNR, model_file='',\n",
    "#                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu, psf_hdu=psf_hdu,\n",
    "#                        image_dim=96, image_per_row=100,\n",
    "#                        deconv_mode=deconv_mode)\n",
    "#Here the number of epochs is set to 2, should be on the order of 20 at the end\n",
    "\n",
    "dnn.train_generator(gal_files[2:], gal_files[1], epochs=20, batch_size=32,\n",
    "                        model_file='', nb_img_per_file=10000, \n",
    "                        validation_set_size=10000, noise_std=None, SNR=SNR, \n",
    "                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu,\n",
    "                        psf_hdu=psf_hdu, image_dim=96, image_per_row=100,\n",
    "                        deconv_mode=deconv_mode, win_validation_filename=win_files[1],\n",
    "                        win_filename=win_files[2:],win_hdu=0,mom_hdu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_scales = 4 #4\n",
    "growth_rate = 12 #12\n",
    "nb_layers_per_block = [5,5,5,5]#[4,5,6,7]\n",
    "activation_function= 'relu' #'relu'\n",
    "gamma=0.01\n",
    "shape_constraint=True\n",
    "atrou=False\n",
    "resNet=False\n",
    "layer_string='layer{0}'.format(nb_layers_per_block[0])\n",
    "\n",
    "\n",
    "for k in range(1,len(nb_layers_per_block)):\n",
    "    layer_string+='x{0}'.format(nb_layers_per_block[k])\n",
    "network_name='ShapeNet2D_claire_sc{0}_{1}_{2}_growthRate{3}_with_shape_gamma{4}'.format(nb_scales,layer_string,\n",
    "                                                                               activation_function,growth_rate,gamma)\n",
    "if resNet:\n",
    "    network_name+='_resNet'\n",
    "\n",
    "dnn= DeconvNet(network_name = network_name, img_rows = 96, img_cols = 96, model_file='', verbose=True,\n",
    "                nb_scales=nb_scales, growth_rate=growth_rate, nb_layers_per_block=nb_layers_per_block, \n",
    "                activation_function=activation_function,resNet=resNet,atrou=atrou,gamma=gamma,\n",
    "                shape_constraint=shape_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the directory containing the fits file\n",
    "data_directory = '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/'\n",
    "write_path=\"/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/\"\n",
    "\n",
    "#Retrieves the list of all the files\n",
    "import glob\n",
    "\n",
    "gal_files = glob.glob(data_directory+'image-*-multihdu.fits')\n",
    "gal_files.sort()\n",
    "print(gal_files)\n",
    "\n",
    "win_files = glob.glob(write_path+'window/'+'Gaussian*')\n",
    "win_files.sort()\n",
    "print(win_files)\n",
    "\n",
    "\n",
    "SNR = [20,100]#Range of SNR simulated\n",
    "noiseless_img_hdu = 0\n",
    "psf_hdu = 1\n",
    "targets_hdu = 2\n",
    "deconv_mode = 'TIKHONOV'\n",
    "\n",
    "#Train with the image-000-0.fits as validation and all the other files as training set\n",
    "#dnn.train_generator(gal_files[1:], gal_files[0], epochs=20, batch_size=32,\n",
    "#                        nb_img_per_file=10000, validation_set_size=10000,\n",
    "#                        noise_std=None, SNR=SNR, model_file='',\n",
    "#                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu, psf_hdu=psf_hdu,\n",
    "#                        image_dim=96, image_per_row=100,\n",
    "#                        deconv_mode=deconv_mode)\n",
    "#Here the number of epochs is set to 2, should be on the order of 20 at the end\n",
    "\n",
    "dnn.train_generator(gal_files[2:], gal_files[1], epochs=20, batch_size=32,\n",
    "                        model_file='', nb_img_per_file=10000, \n",
    "                        validation_set_size=10000, noise_std=None, SNR=SNR, \n",
    "                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu,\n",
    "                        psf_hdu=psf_hdu, image_dim=96, image_per_row=100,\n",
    "                        deconv_mode=deconv_mode, win_validation_filename=win_files[1],\n",
    "                        win_filename=win_files[2:],win_hdu=0,mom_hdu=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapeNet2D_claire_sc3_layer3x3x3_relu_growthRate6_add_shape\n",
      "ShapeNet2D_claire_sc3_layer3x3x3_relu_growthRate6_add_shape\n",
      "0.1\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "print(dnn.network_name)\n",
    "dnn.network_name='ShapeNet2D_claire_sc3_layer3x3x3_relu_growthRate6_add_shape'\n",
    "print(dnn.network_name)\n",
    "print(dnn.gamma)\n",
    "dnn.gamma = 0.1\n",
    "print(dnn.gamma)\n",
    "dnn.shape_loss\n",
    "dnn.model=load_model('ShapeNet2D_claire_sc3_layer3x3x3_relu_growthRate6_pre_shape.hdf5', custom_objects={\"shape_loss\":dnn.shape_loss},compile=False)\n",
    "initial_epoch=3\n",
    "\n",
    "# dnn.train_generator(gal_files[2:4], gal_files[1], epochs=5, batch_size=32,\n",
    "#                       model_file='', nb_img_per_file=1000, \n",
    "#                       validation_set_size=10000, noise_std=None, SNR=SNR, \n",
    "#                       noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu,\n",
    "#                       psf_hdu=psf_hdu, image_dim=96, image_per_row=100,\n",
    "#                       deconv_mode=deconv_mode, win_validation_filename=win_files[1],\n",
    "#                       win_filename=win_files[2:],win_hdu=0,mom_hdu=1,initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss_4/conv2d_48_loss/strided_slice_2:0\", shape=(96, 96), dtype=float32) Tensor(\"loss_4/conv2d_48_loss/strided_slice:0\", shape=(96, 96, 1), dtype=float32) Tensor(\"loss_4/conv2d_48_loss/strided_slice_1:0\", shape=(96, 96, 1), dtype=float32) Tensor(\"loss_4/conv2d_48_loss/sub:0\", shape=(?, 96, 96, ?), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index out of range using input dim 3; input has only 3 dims for 'loss_4/conv2d_48_loss/strided_slice_3' (op: 'StridedSlice') with input shapes: [96,96,1], [4], [4], [4] and with computed input tensors: input[3] = <1 1 1 1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Index out of range using input dim 3; input has only 3 dims for 'loss_4/conv2d_48_loss/strided_slice_3' (op: 'StridedSlice') with input shapes: [96,96,1], [4], [4], [4] and with computed input tensors: input[3] = <1 1 1 1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6ab851b38b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_metric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/deep-deconv/python/DeepDeconv/deepnetFCS/DeepNet.py\u001b[0m in \u001b[0;36mshape_loss\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mtemp\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;31m#print(\"MSE+SHAPE\",K.int_shape(K.expand_dims(temp, axis=-1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   8520\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8521\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8522\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   8523\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8524\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/home/fsureau/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Index out of range using input dim 3; input has only 3 dims for 'loss_4/conv2d_48_loss/strided_slice_3' (op: 'StridedSlice') with input shapes: [96,96,1], [4], [4], [4] and with computed input tensors: input[3] = <1 1 1 1>."
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras import metrics\n",
    "dnn.model.compile(optimizer = Adam(lr=1e-3), loss = dnn.shape_loss, metrics=[metrics.mse,dnn.shape_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 96, 96, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 96, 96, 32)   288         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 96, 96, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 96, 96, 32)   0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_130 (Separable (None, 96, 96, 6)    480         activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 96, 96, 6)    24          separable_conv2d_130[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 96, 96, 6)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_131 (Separable (None, 96, 96, 6)    90          activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 96, 96, 12)   0           separable_conv2d_130[0][0]       \n",
      "                                                                 separable_conv2d_131[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 96, 96, 12)   48          concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 96, 96, 12)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_132 (Separable (None, 96, 96, 6)    180         activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 96, 96, 18)   0           concatenate_123[0][0]            \n",
      "                                                                 separable_conv2d_132[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 96, 96, 50)   0           conv2d_43[0][0]                  \n",
      "                                                                 concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 96, 96, 50)   200         concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 96, 96, 50)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 96, 96, 50)   2500        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 48, 48, 50)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 48, 48, 50)   200         average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 48, 48, 50)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_133 (Separable (None, 48, 48, 6)    750         activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 48, 48, 6)    24          separable_conv2d_133[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 48, 48, 6)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_134 (Separable (None, 48, 48, 6)    90          activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 48, 48, 12)   0           separable_conv2d_133[0][0]       \n",
      "                                                                 separable_conv2d_134[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 48, 48, 12)   48          concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 48, 48, 12)   0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_135 (Separable (None, 48, 48, 6)    180         activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 48, 48, 18)   0           concatenate_126[0][0]            \n",
      "                                                                 separable_conv2d_135[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 48, 48, 68)   0           average_pooling2d_15[0][0]       \n",
      "                                                                 concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 48, 48, 68)   272         concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 48, 48, 68)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 48, 48, 68)   4624        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 24, 24, 68)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 24, 24, 68)   272         average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 24, 24, 68)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_136 (Separable (None, 24, 24, 6)    1020        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 24, 24, 6)    24          separable_conv2d_136[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 24, 24, 6)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_137 (Separable (None, 24, 24, 6)    90          activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 24, 24, 12)   0           separable_conv2d_136[0][0]       \n",
      "                                                                 separable_conv2d_137[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 24, 24, 12)   48          concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 24, 24, 12)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_138 (Separable (None, 24, 24, 6)    180         activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 24, 24, 18)   0           concatenate_129[0][0]            \n",
      "                                                                 separable_conv2d_138[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 48, 48, 18)   0           concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 48, 48, 18)   1314        up_sampling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 48, 48, 86)   0           conv2d_46[0][0]                  \n",
      "                                                                 concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 48, 48, 86)   344         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 48, 48, 86)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_139 (Separable (None, 48, 48, 6)    1290        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 48, 48, 6)    24          separable_conv2d_139[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 48, 48, 6)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_140 (Separable (None, 48, 48, 6)    90          activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 48, 48, 12)   0           separable_conv2d_139[0][0]       \n",
      "                                                                 separable_conv2d_140[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 48, 48, 12)   48          concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 48, 48, 12)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_141 (Separable (None, 48, 48, 6)    180         activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 48, 48, 18)   0           concatenate_132[0][0]            \n",
      "                                                                 separable_conv2d_141[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 96, 96, 18)   0           concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 96, 96, 18)   1314        up_sampling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 96, 96, 68)   0           conv2d_47[0][0]                  \n",
      "                                                                 concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 96, 96, 68)   272         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 96, 96, 68)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_142 (Separable (None, 96, 96, 6)    1020        activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 96, 96, 6)    24          separable_conv2d_142[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 96, 96, 6)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_143 (Separable (None, 96, 96, 6)    90          activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 96, 96, 12)   0           separable_conv2d_142[0][0]       \n",
      "                                                                 separable_conv2d_143[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 96, 96, 12)   48          concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 96, 96, 12)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_144 (Separable (None, 96, 96, 6)    180         activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 96, 96, 18)   0           concatenate_135[0][0]            \n",
      "                                                                 separable_conv2d_144[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 96, 96, 18)   72          concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 96, 96, 18)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 96, 96, 1)    19          activation_168[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 18,089\n",
      "Trainable params: 17,029\n",
      "Non-trainable params: 1,060\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f586aad2240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_scales = 4 #4\n",
    "growth_rate = 12 #12\n",
    "nb_layers_per_block = [4,5,6,7]#[4,5,6,7]\n",
    "activation_function= 'relu' #'relu'\n",
    "gamma=0.01\n",
    "shape_constraint=True\n",
    "atrou=False\n",
    "resNet=False\n",
    "layer_string='layer{0}'.format(nb_layers_per_block[0])\n",
    "\n",
    "\n",
    "for k in range(1,len(nb_layers_per_block)):\n",
    "    layer_string+='x{0}'.format(nb_layers_per_block[k])\n",
    "network_name='ShapeNet2D_claire_sc{0}_{1}_{2}_growthRate{3}_with_shape_gamma{4}'.format(nb_scales,layer_string,\n",
    "                                                                               activation_function,growth_rate,gamma)\n",
    "if resNet:\n",
    "    network_name+='_resNet'\n",
    "\n",
    "dnn= DeconvNet(network_name = network_name, img_rows = 96, img_cols = 96, model_file='', verbose=True,\n",
    "                nb_scales=nb_scales, growth_rate=growth_rate, nb_layers_per_block=nb_layers_per_block, \n",
    "                activation_function=activation_function,resNet=resNet,atrou=atrou,gamma=gamma,\n",
    "                shape_constraint=shape_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the directory containing the fits file\n",
    "data_directory = '/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/'\n",
    "write_path=\"/data/DeepDeconv/data/vsc_euclidpsfs/reshuffle/\"\n",
    "\n",
    "#Retrieves the list of all the files\n",
    "import glob\n",
    "\n",
    "gal_files = glob.glob(data_directory+'image-*-multihdu.fits')\n",
    "gal_files.sort()\n",
    "print(gal_files)\n",
    "\n",
    "win_files = glob.glob(write_path+'window/'+'Gaussian*')\n",
    "win_files.sort()\n",
    "print(win_files)\n",
    "\n",
    "\n",
    "SNR = [20,100]#Range of SNR simulated\n",
    "noiseless_img_hdu = 0\n",
    "psf_hdu = 1\n",
    "targets_hdu = 2\n",
    "deconv_mode = 'TIKHONOV'\n",
    "\n",
    "#Train with the image-000-0.fits as validation and all the other files as training set\n",
    "#dnn.train_generator(gal_files[1:], gal_files[0], epochs=20, batch_size=32,\n",
    "#                        nb_img_per_file=10000, validation_set_size=10000,\n",
    "#                        noise_std=None, SNR=SNR, model_file='',\n",
    "#                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu, psf_hdu=psf_hdu,\n",
    "#                        image_dim=96, image_per_row=100,\n",
    "#                        deconv_mode=deconv_mode)\n",
    "#Here the number of epochs is set to 2, should be on the order of 20 at the end\n",
    "\n",
    "dnn.train_generator(gal_files[2:4], gal_files[1], epochs=3, batch_size=32,\n",
    "                        model_file='', nb_img_per_file=1000, \n",
    "                        validation_set_size=10000, noise_std=None, SNR=SNR, \n",
    "                        noiseless_img_hdu=noiseless_img_hdu, targets_hdu=targets_hdu,\n",
    "                        psf_hdu=psf_hdu, image_dim=96, image_per_row=100,\n",
    "                        deconv_mode=deconv_mode, win_validation_filename=win_files[1],\n",
    "                        win_filename=win_files[2:],win_hdu=0,mom_hdu=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is to train a network for Tikhonov post processing.\n",
    "\n",
    "If you want to train a denoiser on the ground truth images simply set:\n",
    "\n",
    "    deconv_mode = None\n",
    "\n",
    "    noiseless_img_hdu = target_hdu = 2\n",
    "\n",
    "you do not need to provide the PSFs for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here some remarks about the memory usage if you work on GPUs\n",
    "\n",
    "We have limited amount of VRAM on our GPUs (5GB for the Tesla K20c in the SAPPCN63 and 8GB on the Quadro P4000 in the DAPPCW149).\n",
    "\n",
    "Inside the DeepNet class, there is a function computing the memory required for the model given its architecture and the size of one batch of data. This function is called automatically at the start of the training methods. It gives a rough idea of how much memory you will need to train the network. Keep in mind that it is only the memory needed for loading the parameters and on batch of data. All the intermediate computation will require as much if not more memory to do the training correctly.\n",
    "\n",
    "If you use too much memory, either tensorflow will return a warning saying the memory is full but it can still optimize the training by itself to run, or it will return an OOM error and crash. In both case, the best is to try to optimize the memory allocation by either reducing the number of parameters of the DNN or the batch size.\n",
    "\n",
    "Note that by default, when you start a Tensorflow session, it will try to pre-allocate 100% of the available GPU memory even when it doesn't need it all. Use the following bit of code to solve this issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extra imports to set GPU options\n",
    "#import tensorflow as tf\n",
    "#from keras import backend as k\n",
    "\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "#config = tf.ConfigProto()\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "#config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# This line is optional, don't add it unless you really need to set a limit on the memory available for your process\n",
    "# For instance, if you want to train 2 DNNs on the same GPU without one overlapping the memory needed by the other\n",
    "# Change the value to set the percentage of memory allocated\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5 \n",
    "\n",
    "# Create a session with the above options specified.\n",
    "#k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "# Now you can create/load your DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with multiple GPUs, Tensorflow will pre-allocate the whole memory of all the GPUs.\n",
    "Use the following to prevent it (only when your station has several GPUs like the SAPPCN63):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #\"0\" for the 1st GPU or \"1\" to use the 2nd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
