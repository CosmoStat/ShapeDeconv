{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Comparison between Numpy and Tensorflow\n",
    "\n",
    "This document aims to compare the losses that are used in SCORE and ShapeDeconv and ultimately harmonize them.\n",
    "\n",
    "## Load present losses\n",
    "\n",
    "<b>Note:</b> Only the differentiable part of the loss is considered is the case of SCORE.\n",
    "\n",
    "Setting required constants and variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fnammour/Documents/GitHub/score/cadmos_lib.py:104: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  coeff[s] = trafo.adjoint_transform(temp, do_norm=False)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import cadmos_lib as cl\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# declare constants that are common for single and multi window constraint\n",
    "n_row = n_col = 96\n",
    "gamma = 1\n",
    "U = cl.makeUi(n_row,n_col)\n",
    "\n",
    "# generate mock data\n",
    "y_pred,win = np.random.rand(2,3,n_row,n_col)\n",
    "y_true = np.zeros((3,n_row,n_col))\n",
    "residual = y_true-y_pred\n",
    "\n",
    "#declare constants that are specific to single window constraint\n",
    "muw = np.array([y_pred.size/norm(win*Ui)**2/U.shape[0] for Ui in U])\n",
    "\n",
    "#declare constants that are specific to single window constraint\n",
    "n_shearlet = 3\n",
    "shearlets,shearlets_adj = cl.get_shearlets(n_row,n_col,n_shearlet)\n",
    "psu = np.array([cl.convolve_stack(ui,shearlets_adj) for ui in U]) #shealret adjoint of U, i.e Psi^{Star}(U)\n",
    "mus = cl.comp_mu(psu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Single Window SCORE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_fid= [1546.1110829319493, 1564.7831197659116, 1559.7051593505662]\n",
      "shape_constraint= [ 998300.53418549 1027748.57909154 1367522.40986093]\n",
      "loss= [ 999846.64526842 1029313.36221131 1369082.11502028]\n"
     ]
    }
   ],
   "source": [
    "def loss_SW_score(residual):\n",
    "    data_fid = [norm(r)**2/2. for r in residual]\n",
    "    print(\"data_fid=\",data_fid)\n",
    "    shape_constraint = gamma*(np.array([m*((r*w*u).sum())**2\n",
    "                                        for r,m,u,w in zip(residual,muw,U,win)])/2.)\n",
    "    print(\"shape_constraint=\",shape_constraint)\n",
    "    return data_fid+shape_constraint\n",
    "\n",
    "print(\"loss=\",loss_SW_score(residual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rewriting Single Window ShapeDecon Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_fid= [1546.11108293]\n",
      "shape_constraint= [4983510.50694212]\n",
      "data_fid= [1564.78311977]\n",
      "shape_constraint= [5099637.54558196]\n",
      "data_fid= [1559.70515935]\n",
      "shape_constraint= [5098536.95031807]\n",
      "loss= [array([4985056.61802505]), array([5101202.32870172]), array([5100096.65547742])]\n"
     ]
    }
   ],
   "source": [
    "def loss_SW_keras(y_pred,y_true):\n",
    "    y_pred = tf.reshape(y_pred, [1,*y_pred.shape,1])\n",
    "    y_true = tf.reshape(y_true, [1,*y_true.shape,1])\n",
    "    residual = y_true-y_pred\n",
    "    data_fid = tf.keras.backend.sum(tf.keras.backend.square(y_true-y_pred),axis=(1,2,3))/2.\n",
    "    window = tf.reshape(win[0], [1,*win.shape[1:],1])\n",
    "    U_tensor = tf.reshape(U, [U.shape[0],1,*U.shape[1:],1])\n",
    "    mu = tf.reshape(muw, [*muw.shape])\n",
    "    shape_constraint=0\n",
    "    for i in range(6):\n",
    "        shape_constraint+=gamma*mu[i]*\\\n",
    "        tf.keras.backend.square(\n",
    "            (tf.keras.backend.sum(residual*window*U_tensor[i],axis=(1,2,3))))/2\n",
    "    print(\"shape_constraint=\",tf.keras.backend.get_value(shape_constraint))\n",
    "    return data_fid+shape_constraint\n",
    "\n",
    "print(\"loss=\",[tf.keras.backend.get_value(loss_SW_keras(yp,yt)) for yp,yt in zip(y_pred,y_true)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multi Window SCORE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_fid= 1532.8932077213979\n",
      "shape_constraint= 2646.1208671422955\n",
      "loss= 4179.014074863693\n"
     ]
    }
   ],
   "source": [
    "def loss_MW_score(residual):\n",
    "    data_fid = np.linalg.norm(residual)**2/2.\n",
    "    print(\"data_fid=\",data_fid)\n",
    "    shape_constraint = gamma*(np.array(\\\n",
    "            [[mu_ij*((residual*psu_ij).sum())**2\\\n",
    "              for mu_ij,psu_ij in zip(mu_j, psu_j)]\\\n",
    "            for mu_j,psu_j in zip(mus,psu)])/2.).sum()\n",
    "    print(\"shape_constraint=\",shape_constraint)\n",
    "    loss = data_fid+shape_constraint\n",
    "    return loss\n",
    "\n",
    "print(\"loss=\",loss_MW_score(residual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rewriting Multi Window ShapeDecon Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_fid= [1532.89320772]\n",
      "shape_constraint= [2646.12086714]\n",
      "loss= [4179.01407486]\n"
     ]
    }
   ],
   "source": [
    "def loss_MW_keras(y_pred,y_true):\n",
    "    y_pred = tf.reshape(y_pred, [1,*y_pred.shape,1])\n",
    "    y_true = tf.reshape(y_true, [1,*y_true.shape,1])\n",
    "    mu = tf.reshape(mus, [*mus.shape])\n",
    "    psu_tensor = tf.reshape(psu, [*psu.shape[:2],1,*psu.shape[2:],1])\n",
    "    residual=y_pred-y_true\n",
    "    data_fid = tf.keras.backend.sum(tf.keras.backend.square(y_true-y_pred),axis=(1,2,3))/2.\n",
    "    print(\"data_fid=\",tf.keras.backend.get_value(data_fid))\n",
    "    shape_constraint=0\n",
    "    for i in range(6):\n",
    "        for j in range(27):\n",
    "            shape_constraint+=gamma*mu[i,j]*\\\n",
    "            tf.keras.backend.square(\n",
    "                tf.keras.backend.sum(residual*psu_tensor[i,j],axis=(1,2,3)))/2.\n",
    "    print(\"shape_constraint=\",tf.keras.backend.get_value(shape_constraint))\n",
    "    loss=data_fid+shape_constraint\n",
    "    return loss\n",
    "\n",
    "print(\"loss=\",tf.keras.backend.get_value(loss_MW_keras(y_pred,y_true)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
